---
title: "Introduction"
teaching: 0
exercises: 0
questions:
- "Key question (FIXME)"
objectives:
- "First learning objective. (FIXME)"
keypoints:
- "First key point. Brief Answer to questions. (FIXME)"
---

**How do we infer information from data?**

This is a core question of any scientific research. How do we go from the data collected 
to knowledge about the world around us? Knowledge in this context could mean the result of a medical
study testing the efficacy of a new drug, it could mean the outcome of a physics experiment, or
using observations of exploding stars to tell us something about the expansion of the universe. 

One key element binding together **data** and **knowledge** is statistics. Statistics helps us
understand and take into account randomness in our measurement device and uncertainty about the
world around us. It helps us quantify how certain we can be in a result derived from data.

This tutorial aims to give a short and gentle introduction into Bayesian statistics, one framework
of statistical inference and decision making that has become increasingly popular in recent years. 

This tutorial owes a lot to previous Bayesian statistics tutorials at [Astro Hack Week][ahw],
especially Brendon Brewer's [tutorial][bayes2015] in 2015 and Ruth Angus' [tutorial][bayes2018] in
2018. It is also directly based on the paper ["Introducing Bayesian Statistics with M&Ms][mmpaper]
by Gwen Eadie et al (2019). Because what better way to learn statistics than through chocolate?  


[mmpaper]: https://www.tandfonline.com/doi/full/10.1080/10691898.2019.1604106
[bayes2015]: https://github.com/AstroHackWeek/AstroHackWeek2015/tree/master/day4-day5-inference
[bayes2018]: https://github.com/AstroHackWeek/AstroHackWeek2018/tree/master/day2_bayesian_inference

{% include links.md %}
